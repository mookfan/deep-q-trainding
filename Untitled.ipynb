{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9578fdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/29/23 17:50:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'test_df'</span> <span style=\"font-weight: bold\">(</span>ParquetDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <a href=\"file:///opt/anaconda3/envs/deepq/lib/python3.8/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/deepq/lib/python3.8/site-packages/kedro/io/data_catalog.py#343\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/29/23 17:50:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'test_df'\u001b[0m \u001b[1m(\u001b[0mParquetDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b]8;id=300423;file:///opt/anaconda3/envs/deepq/lib/python3.8/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=649529;file:///opt/anaconda3/envs/deepq/lib/python3.8/site-packages/kedro/io/data_catalog.py#343\u001b\\\u001b[2m343\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = catalog.load(\"test_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abe0330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-30T02:00:00Z</th>\n",
       "      <td>9.65</td>\n",
       "      <td>9.70</td>\n",
       "      <td>9.50</td>\n",
       "      <td>35.338566</td>\n",
       "      <td>44.366060</td>\n",
       "      <td>5054758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31T02:00:00Z</th>\n",
       "      <td>9.55</td>\n",
       "      <td>9.70</td>\n",
       "      <td>9.45</td>\n",
       "      <td>34.777051</td>\n",
       "      <td>42.840267</td>\n",
       "      <td>10414234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01T02:00:00Z</th>\n",
       "      <td>9.35</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.30</td>\n",
       "      <td>34.582919</td>\n",
       "      <td>39.885808</td>\n",
       "      <td>15898069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02T02:00:00Z</th>\n",
       "      <td>9.40</td>\n",
       "      <td>9.40</td>\n",
       "      <td>9.30</td>\n",
       "      <td>34.402653</td>\n",
       "      <td>40.981624</td>\n",
       "      <td>3264543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-06T02:00:00Z</th>\n",
       "      <td>9.35</td>\n",
       "      <td>9.45</td>\n",
       "      <td>9.30</td>\n",
       "      <td>34.010371</td>\n",
       "      <td>40.192598</td>\n",
       "      <td>1776453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-28T02:00:00Z</th>\n",
       "      <td>13.40</td>\n",
       "      <td>13.40</td>\n",
       "      <td>13.20</td>\n",
       "      <td>21.702183</td>\n",
       "      <td>61.642682</td>\n",
       "      <td>3045594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29T02:00:00Z</th>\n",
       "      <td>13.40</td>\n",
       "      <td>13.40</td>\n",
       "      <td>13.20</td>\n",
       "      <td>22.278455</td>\n",
       "      <td>61.642682</td>\n",
       "      <td>2345537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30T02:00:00Z</th>\n",
       "      <td>13.10</td>\n",
       "      <td>13.40</td>\n",
       "      <td>13.10</td>\n",
       "      <td>22.295488</td>\n",
       "      <td>54.805689</td>\n",
       "      <td>2626446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31T02:00:00Z</th>\n",
       "      <td>13.30</td>\n",
       "      <td>13.30</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.814464</td>\n",
       "      <td>58.139077</td>\n",
       "      <td>3787206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03T02:00:00Z</th>\n",
       "      <td>13.10</td>\n",
       "      <td>13.30</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.367798</td>\n",
       "      <td>53.860885</td>\n",
       "      <td>3270709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      close   high    low     ADX_14     RSI_14    Volume\n",
       "time                                                                     \n",
       "2022-05-30T02:00:00Z   9.65   9.70   9.50  35.338566  44.366060   5054758\n",
       "2022-05-31T02:00:00Z   9.55   9.70   9.45  34.777051  42.840267  10414234\n",
       "2022-06-01T02:00:00Z   9.35   9.65   9.30  34.582919  39.885808  15898069\n",
       "2022-06-02T02:00:00Z   9.40   9.40   9.30  34.402653  40.981624   3264543\n",
       "2022-06-06T02:00:00Z   9.35   9.45   9.30  34.010371  40.192598   1776453\n",
       "...                     ...    ...    ...        ...        ...       ...\n",
       "2023-03-28T02:00:00Z  13.40  13.40  13.20  21.702183  61.642682   3045594\n",
       "2023-03-29T02:00:00Z  13.40  13.40  13.20  22.278455  61.642682   2345537\n",
       "2023-03-30T02:00:00Z  13.10  13.40  13.10  22.295488  54.805689   2626446\n",
       "2023-03-31T02:00:00Z  13.30  13.30  13.00  21.814464  58.139077   3787206\n",
       "2023-04-03T02:00:00Z  13.10  13.30  13.00  21.367798  53.860885   3270709\n",
       "\n",
       "[209 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b7423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class YourModel(nn.Module):\n",
    "    def __init__(self, state_size, feature_size, action_size):\n",
    "        super(YourModel, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.feature_size = feature_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.state_size * self.feature_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 3)\n",
    "        self.fc4 = nn.Linear(3, self.action_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bdb39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    " def cnn_model(self):\n",
    "        # model =  nn.Sequential(\n",
    "        #             nn.Linear(self.state_size * self.feature_size, 16),   # input size: 14 x 2 = 28, output size: 16\n",
    "        #             nn.Linear(16, 8),\n",
    "        #             nn.Linear(8, 3),\n",
    "        #             nn.Linear(3, self.action_size),\n",
    "        #             nn.ReLU())\n",
    "        # model =  nn.Sequential(\n",
    "        #             nn.Linear(self.state_size * self.feature_size, 16),   # input size: 14 x 2 = 28, output size: 16\n",
    "        #             nn.ReLU(),\n",
    "        #             nn.Linear(16, 8),    # input size: 16, output size: 8\n",
    "        #             nn.ReLU(),\n",
    "        #             nn.Linear(8, 3),     # input size: 8, output size: 3\n",
    "        #             nn.ReLU(),\n",
    "        #             nn.Linear(3, 3),     # input size: 3, output size: 3\n",
    "        #             nn.ReLU(),\n",
    "        #             nn.Linear(3, 3),     # input size: 3, output size: 3\n",
    "        #             nn.ReLU(),\n",
    "        #             nn.Linear(3, self.action_size),     # input size: 3, output size: 3\n",
    "        #         )\n",
    "        # print(\"\\n========= Model Summary ==========\")\n",
    "        # print(\"Input size: \", self.state_size * self.feature_size)\n",
    "        # print(summary(model, input_size=(1, self.state_size * self.feature_size), batch_size=self.batch_size))\n",
    "        # print(\"\\n\")\n",
    "        # return model\n",
    "        model = YourModel(self.state_size, self.feature_size, self.action_size)\n",
    "        print(\"\\n========= Model Summary ==========\")\n",
    "        print(\"Input size: \", self.state_size * self.feature_size)\n",
    "        print(summary(model, input_size=(1, self.state_size * self.feature_size), batch_size=self.batch_size))\n",
    "        print(\"\\n\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e1a17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326858b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70dd8c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 4.7950e-01,  4.4136e-01,  4.9196e-01, -2.3496e-01, -8.4166e-02,\n",
       "                        1.5799e-01,  3.9230e-01,  4.1542e-01,  4.8226e-01, -3.1090e-02,\n",
       "                        6.4230e-02,  1.7059e-01,  4.5417e-01,  2.2633e-01,  3.2338e-01,\n",
       "                       -7.9119e-02,  4.8534e-02,  2.8505e-02,  3.4188e-01,  1.6534e-01,\n",
       "                        2.6711e-01,  6.7648e-02,  6.2592e-02,  2.6408e-01,  3.1517e-01,\n",
       "                        1.5623e-01,  2.1378e-01, -1.6345e-01,  1.6641e-01,  3.3154e-01,\n",
       "                        3.5226e-01,  2.6380e-01,  3.0567e-01,  7.5141e-02,  1.0483e-01,\n",
       "                        5.8405e-01,  2.2439e-01,  2.1447e-01,  3.0789e-01, -5.8400e-02,\n",
       "                        5.9764e-02,  1.8191e-01,  2.8334e-01,  1.6102e-01,  1.4076e-01,\n",
       "                       -2.6985e-02,  9.0304e-02, -1.5981e-01,  1.6830e-01,  1.1936e-01,\n",
       "                        1.9456e-01,  5.2185e-02,  7.6783e-02,  1.5501e-02,  2.4149e-01,\n",
       "                        2.9535e-01,  2.9931e-01,  2.1093e-01, -1.9080e-03,  3.4646e-01],\n",
       "                      [ 8.3355e-02,  4.5099e-02,  7.0844e-02, -1.7968e-01, -1.6940e-01,\n",
       "                       -3.4414e-01, -8.9821e-02, -1.1845e-01,  1.3693e-01, -2.5098e-01,\n",
       "                       -1.8582e-02, -2.8000e-01, -5.0467e-02, -2.8385e-02,  8.1995e-02,\n",
       "                       -1.5583e-01, -7.1797e-03, -1.3314e-01,  6.7457e-02, -9.2320e-02,\n",
       "                       -6.2183e-02, -1.1801e-01, -1.1933e-01, -1.5732e-01, -2.4795e-02,\n",
       "                       -1.3464e-02, -1.4601e-03, -1.4989e-01, -2.2574e-01,  1.0006e-01,\n",
       "                       -4.4716e-02, -6.0908e-02,  2.2914e-03, -2.6049e-01, -1.3686e-01,\n",
       "                       -1.0086e-01, -2.3234e-01,  3.7480e-02,  2.2471e-02, -2.9750e-01,\n",
       "                       -1.5611e-01, -5.2548e-02, -6.6715e-02, -3.1002e-02, -2.1419e-01,\n",
       "                       -2.6707e-01, -5.3091e-02,  3.6510e-03, -1.9353e-02, -2.3562e-01,\n",
       "                       -1.3772e-01, -7.4125e-02, -9.7872e-02, -9.8387e-02, -1.1885e-01,\n",
       "                       -5.1162e-02, -3.7903e-02, -1.4293e-01, -1.4416e-01,  3.2752e-02],\n",
       "                      [ 2.5437e-02, -2.6930e-02,  5.2840e-02,  3.7219e-02,  4.8643e-02,\n",
       "                       -2.2213e-02,  4.3780e-03, -9.3756e-03,  4.9767e-02, -3.7967e-02,\n",
       "                       -1.1518e-01,  3.0938e-02,  1.0960e-02, -1.2747e-01,  1.1007e-01,\n",
       "                        6.8847e-02, -6.0245e-02, -3.3414e-02, -1.0645e-02, -1.0145e-01,\n",
       "                       -4.5613e-02, -4.3609e-02, -3.9848e-02,  5.7034e-02, -7.3308e-02,\n",
       "                        7.5499e-02,  1.0755e-01, -6.4898e-02, -4.4784e-02,  8.1443e-02,\n",
       "                        9.9381e-03, -5.6851e-02, -3.0838e-02, -6.6930e-02, -2.9749e-02,\n",
       "                        8.9651e-02, -9.4282e-02,  1.0135e-02,  1.0379e-01,  3.5055e-02,\n",
       "                        6.0965e-02,  1.1585e-01, -8.1744e-02, -9.7108e-02,  5.8195e-02,\n",
       "                       -2.4692e-02,  1.2976e-02,  4.9046e-02, -1.2358e-01, -5.2496e-02,\n",
       "                        1.4631e-02, -1.0695e-01, -8.8477e-02,  1.0767e-01, -8.6352e-02,\n",
       "                       -1.1212e-01, -1.1024e-01, -7.1913e-03,  1.0961e-01,  1.1208e-02],\n",
       "                      [-1.1272e-01,  1.9573e-02, -2.5657e-02,  9.8672e-02, -2.3653e-01,\n",
       "                       -4.8577e-01, -1.9967e-01,  7.9020e-03,  1.5765e-02,  1.3990e-01,\n",
       "                       -1.4582e-01, -5.4950e-01, -1.5917e-01, -1.5047e-01, -3.5865e-02,\n",
       "                        1.3648e-01, -1.5538e-01, -2.6175e-01, -2.8264e-01, -2.4261e-01,\n",
       "                       -1.8838e-01, -5.9656e-02, -2.1855e-01, -1.2695e-01, -1.1474e-01,\n",
       "                       -2.5166e-01, -8.1972e-02, -5.3263e-02, -1.5491e-01, -3.3558e-01,\n",
       "                       -2.4154e-01, -1.1717e-01, -8.3640e-02,  7.0014e-02, -2.5240e-02,\n",
       "                       -1.7870e-01, -3.3441e-01, -2.0640e-01, -9.6769e-02, -7.1737e-02,\n",
       "                       -3.8566e-02, -2.4472e-01, -2.1962e-01, -3.0561e-01, -7.2063e-02,\n",
       "                       -1.2888e-01, -1.0771e-01, -2.9251e-01, -2.9189e-01, -2.5862e-01,\n",
       "                       -2.7796e-01,  8.1773e-03, -1.3340e-01, -4.5857e-01, -9.8296e-02,\n",
       "                       -2.9154e-01, -6.5590e-02,  2.5266e-02, -1.1436e-01, -2.9351e-01],\n",
       "                      [ 7.3817e-02, -7.3120e-02, -8.4898e-02,  2.3530e-02, -1.5100e-02,\n",
       "                       -1.1088e-01, -1.3918e-01, -1.2312e-01,  8.1056e-03, -1.7302e-02,\n",
       "                       -1.4796e-01, -1.2486e-03,  2.4228e-02, -6.4124e-02,  5.5633e-02,\n",
       "                       -1.9409e-02, -1.2094e-02,  2.7504e-02,  8.3945e-02,  5.9189e-02,\n",
       "                       -4.3615e-02, -5.4018e-02, -1.5034e-01,  3.0445e-02, -8.1893e-02,\n",
       "                       -1.7598e-02,  8.9865e-02, -1.1022e-02,  3.3011e-03, -3.8250e-02,\n",
       "                        1.0200e-02, -7.8958e-02,  8.2229e-02,  4.4530e-04, -1.4440e-01,\n",
       "                       -8.1526e-02, -4.6319e-02,  3.6450e-02, -1.2746e-01, -1.3495e-01,\n",
       "                        1.1041e-02, -1.9816e-02,  5.9112e-02, -2.9678e-02, -1.4896e-01,\n",
       "                        4.3897e-02, -1.3163e-01, -1.5374e-01,  2.4784e-02, -1.0682e-01,\n",
       "                       -6.2296e-02,  4.9365e-02, -5.5682e-02,  2.3545e-02,  2.7017e-02,\n",
       "                       -7.4963e-02,  4.5614e-02, -1.2774e-01, -1.3159e-01, -6.2067e-03],\n",
       "                      [-1.3305e-01,  1.7360e-02, -1.0792e-01,  1.9062e-02,  1.8977e-02,\n",
       "                       -1.5302e-01,  2.9026e-02, -7.4077e-02, -2.7722e-02, -1.4307e-01,\n",
       "                       -4.7467e-02, -8.6604e-02, -8.0087e-02, -5.8404e-02,  3.9320e-02,\n",
       "                       -1.3402e-01,  6.6552e-02,  6.7254e-02, -1.0823e-01,  2.8341e-02,\n",
       "                        7.4467e-02,  3.3711e-03, -4.0454e-03,  3.0793e-04, -1.4037e-01,\n",
       "                        5.2695e-03,  5.4964e-02, -5.2025e-02, -1.0169e-01, -5.5831e-03,\n",
       "                       -1.4212e-01,  4.5260e-02, -1.2035e-01,  1.4543e-02,  5.2633e-02,\n",
       "                       -6.4131e-02, -3.3723e-02, -8.8356e-02,  8.3720e-02,  8.4389e-02,\n",
       "                        1.4068e-02, -1.1235e-02,  2.1338e-02, -8.3142e-02, -1.5237e-01,\n",
       "                        4.4937e-03, -1.4255e-01,  9.8526e-02,  7.4561e-02, -1.5008e-01,\n",
       "                       -1.0093e-01,  4.9237e-02,  7.1497e-02,  9.5822e-02, -9.3986e-02,\n",
       "                        1.2927e-03, -1.2389e-01, -1.0522e-02,  6.8551e-02, -1.0397e-01],\n",
       "                      [-1.0219e-01, -2.2049e-02,  1.0306e-01,  4.0585e-02,  1.7642e-02,\n",
       "                       -3.9371e-02,  5.4688e-02, -7.3677e-02, -4.2885e-02, -2.8041e-02,\n",
       "                       -5.5368e-02,  7.8642e-02,  9.9147e-02, -5.2768e-02,  3.6686e-02,\n",
       "                       -1.5221e-01, -4.0049e-02, -1.1631e-01, -2.6228e-02, -7.9219e-02,\n",
       "                        9.1714e-02, -1.1043e-02,  4.2737e-02,  1.1691e-02, -4.8319e-02,\n",
       "                        9.8573e-03, -2.8059e-03, -1.1585e-01,  4.3754e-02, -1.3856e-01,\n",
       "                       -8.2208e-02, -8.2969e-02, -1.4831e-03,  6.9346e-02, -4.4755e-02,\n",
       "                        6.1960e-02,  9.8964e-02, -2.6466e-03, -1.1141e-01,  9.5653e-02,\n",
       "                       -2.0814e-02,  3.8492e-02, -8.7610e-02,  9.3328e-02, -9.6752e-02,\n",
       "                       -1.1042e-01, -1.0420e-01, -6.7770e-02,  5.4802e-03,  9.6816e-03,\n",
       "                       -1.0328e-01,  7.6221e-02, -6.4335e-02,  1.1401e-01,  1.0659e-01,\n",
       "                       -6.0265e-02,  9.0188e-02, -9.7315e-02,  7.4029e-02, -1.0058e-01],\n",
       "                      [ 7.9564e-02, -4.2759e-02,  5.1402e-02, -8.1363e-02, -1.1615e-01,\n",
       "                        5.2630e-02, -4.7989e-02, -9.8810e-02,  5.4301e-02, -1.4317e-01,\n",
       "                        2.2054e-02,  1.4100e-01,  8.4879e-02, -7.5130e-02, -3.2996e-02,\n",
       "                        2.2514e-02,  7.7178e-02,  1.0848e-01, -9.9527e-02,  3.5187e-02,\n",
       "                       -1.4504e-01, -1.2182e-01, -9.0140e-02,  3.5417e-02,  6.9307e-02,\n",
       "                       -1.3203e-01, -1.1675e-01, -1.5940e-01, -7.4770e-02, -4.5687e-02,\n",
       "                        2.2583e-02, -6.6064e-02,  3.6077e-02,  1.9506e-02,  2.1809e-02,\n",
       "                        9.4348e-02,  2.9887e-02, -1.2085e-01,  1.0539e-01, -1.2669e-01,\n",
       "                       -1.6016e-02,  5.8531e-02, -1.4791e-01,  4.3333e-02,  1.0263e-01,\n",
       "                        5.6224e-02, -5.7750e-02,  1.3425e-02, -9.7859e-02,  3.8630e-02,\n",
       "                       -1.4194e-01, -1.4492e-01, -1.4773e-01,  1.7952e-02, -1.2857e-01,\n",
       "                       -9.2007e-02, -5.5218e-02,  3.1406e-02,  7.7012e-02, -7.3122e-02],\n",
       "                      [ 7.0888e-03, -3.3320e-02,  4.5793e-02, -9.9206e-02, -9.7412e-02,\n",
       "                       -1.5079e-01,  5.0673e-02, -1.1448e-01,  7.0470e-02, -1.7288e-01,\n",
       "                       -4.8014e-02, -9.0867e-02, -7.4803e-02, -1.2266e-01, -6.6383e-02,\n",
       "                       -6.5505e-02, -1.6946e-01,  3.9047e-02, -5.6498e-02,  2.4887e-02,\n",
       "                        3.7296e-02,  7.3329e-02,  6.1920e-02,  2.2198e-02, -1.0068e-01,\n",
       "                       -9.9456e-02, -3.7527e-03,  3.0640e-02, -1.4705e-01,  7.1089e-02,\n",
       "                        4.7914e-02, -4.8192e-02, -3.4423e-02, -5.3003e-02,  7.5207e-02,\n",
       "                       -1.1073e-01, -2.0678e-02, -3.7024e-02, -1.1216e-01, -1.1420e-01,\n",
       "                       -7.4479e-02,  5.7602e-02, -6.0802e-02,  8.1587e-02,  2.2399e-02,\n",
       "                        6.2603e-02, -1.3129e-01, -1.6072e-01, -2.7368e-02,  3.6193e-02,\n",
       "                       -1.6091e-01, -1.7699e-01, -7.0800e-02, -4.8835e-02, -1.1387e-02,\n",
       "                        4.8527e-02,  2.9164e-02, -6.3802e-03,  4.5238e-02, -7.1062e-02],\n",
       "                      [-1.3144e-01, -1.2360e-01, -3.1786e-02,  1.9245e-01, -6.5664e-02,\n",
       "                       -2.0872e-01,  1.3907e-01,  8.3181e-02,  5.0661e-02,  3.2380e-02,\n",
       "                        2.0875e-01, -3.8330e-01,  3.0990e-02, -5.3076e-02,  2.4083e-02,\n",
       "                       -1.1913e-01,  3.5717e-02,  2.8001e-02, -3.7221e-02, -4.0882e-02,\n",
       "                       -6.6579e-02, -1.9157e-01, -6.2161e-02,  3.7258e-02, -1.7101e-01,\n",
       "                       -1.8291e-02, -1.3331e-01, -9.0582e-02,  2.1676e-02,  2.4985e-03,\n",
       "                       -1.0885e-01, -2.8609e-02, -2.2327e-01, -3.0561e-02,  6.1250e-02,\n",
       "                       -1.6150e-02, -9.9710e-02, -2.5170e-01, -7.0524e-02, -1.9838e-01,\n",
       "                        6.5776e-02, -5.4050e-02, -2.1264e-01, -2.0843e-01, -5.6245e-02,\n",
       "                       -1.0866e-01,  5.0721e-02,  7.4792e-02, -2.1621e-01, -1.0442e-01,\n",
       "                       -2.3677e-01, -2.2809e-01,  1.4267e-02, -3.3137e-02, -1.3733e-01,\n",
       "                       -1.3801e-01, -8.9119e-02, -2.9237e-01,  8.5034e-02, -1.2349e-01],\n",
       "                      [-8.5890e-02, -3.8273e-02,  9.0110e-02, -3.1175e-02,  9.4518e-02,\n",
       "                        1.1053e-01,  5.4677e-02,  5.0484e-02, -6.2843e-02,  6.9536e-02,\n",
       "                       -8.1453e-02, -3.2885e-02, -2.2165e-03, -9.2263e-02, -1.0854e-01,\n",
       "                       -1.1586e-01,  6.3005e-03, -1.5028e-02,  6.3060e-02,  7.1388e-02,\n",
       "                       -4.7873e-03, -1.2046e-01,  5.1346e-02,  1.0359e-01, -9.2121e-02,\n",
       "                       -7.5015e-02,  7.4802e-02, -1.3158e-01,  9.6095e-02,  1.0048e-01,\n",
       "                       -1.0566e-01, -1.0514e-01,  6.1597e-02, -5.1793e-02, -2.2432e-02,\n",
       "                        9.2508e-02, -1.0693e-03,  4.7798e-02, -1.2966e-01,  7.5007e-03,\n",
       "                       -1.6494e-02,  6.0138e-02,  7.6647e-02, -1.5519e-02,  1.0127e-01,\n",
       "                        6.4132e-02, -6.4660e-02,  6.6932e-02, -1.0197e-01,  8.1897e-02,\n",
       "                       -1.2812e-01, -2.1769e-03, -5.9407e-02, -7.9411e-02,  1.0388e-01,\n",
       "                        6.5461e-02, -1.0851e-02,  2.4574e-02,  8.2565e-02,  1.0499e-01],\n",
       "                      [-9.6903e-03,  4.2031e-02, -2.4738e-02,  6.2805e-02,  7.2384e-03,\n",
       "                       -7.0744e-02, -1.5285e-01, -7.0279e-02, -1.3108e-01, -1.2159e-01,\n",
       "                        4.5677e-02, -1.7666e-02, -1.4229e-01, -8.9451e-02,  5.5756e-02,\n",
       "                       -3.0837e-02, -1.5781e-02, -1.1884e-01, -1.2795e-01, -1.4348e-01,\n",
       "                       -1.4959e-01,  3.7064e-02,  2.7730e-02, -1.5145e-01,  1.7672e-02,\n",
       "                        6.7099e-02,  6.6335e-02,  7.7387e-02, -6.7386e-02, -3.6849e-02,\n",
       "                       -9.3713e-02,  5.4728e-02, -1.6911e-01, -4.3847e-02,  6.2247e-02,\n",
       "                       -5.6567e-02, -6.1639e-02, -1.2581e-01, -1.2419e-02, -3.1604e-02,\n",
       "                       -3.4083e-02, -3.6930e-03, -8.0818e-02, -5.0521e-02, -4.0141e-02,\n",
       "                       -6.4000e-02, -7.1623e-02, -4.9353e-02, -7.0570e-02,  2.6236e-02,\n",
       "                        1.3239e-02, -6.4997e-02,  3.5328e-03, -4.7043e-02,  2.6672e-03,\n",
       "                        4.7406e-02,  6.2637e-02,  5.5751e-02, -1.4254e-01,  7.3729e-02],\n",
       "                      [ 3.3058e-02, -1.0505e-01, -1.8169e-02,  3.1153e-02, -4.0805e-02,\n",
       "                        3.9685e-02,  1.9509e-02, -7.4186e-02, -1.1266e-02,  5.6921e-02,\n",
       "                        4.1477e-02, -1.6527e-01, -6.0397e-02,  5.2396e-02,  1.6373e-02,\n",
       "                        4.3095e-02, -1.3376e-01, -4.3204e-02, -9.1006e-03, -9.1545e-02,\n",
       "                        4.4646e-02, -1.3702e-02,  1.1408e-02, -1.1582e-01,  1.6907e-03,\n",
       "                       -8.0790e-02, -5.7413e-02,  2.7670e-02, -1.2686e-01, -8.6209e-02,\n",
       "                       -1.0100e-01, -1.3637e-01, -8.4535e-02, -1.4756e-03,  8.4718e-02,\n",
       "                       -1.6453e-01,  5.7425e-02,  5.1601e-02, -1.6593e-02, -1.8211e-01,\n",
       "                       -3.7545e-02, -1.0574e-01, -1.1859e-01, -1.3141e-01,  5.1355e-02,\n",
       "                       -1.7047e-01,  5.7603e-02, -5.2921e-02,  4.4788e-02,  6.4884e-02,\n",
       "                       -1.1968e-01, -4.3912e-02, -7.7222e-02, -1.1268e-01, -3.6735e-02,\n",
       "                        1.8584e-02,  9.5683e-02, -4.2353e-02,  9.6396e-02, -1.5374e-01],\n",
       "                      [-4.3764e-02,  3.7868e-02,  1.0546e-02,  2.2819e-03, -1.3386e-01,\n",
       "                        1.1048e-01,  3.2796e-02, -7.1651e-02,  5.8610e-03, -7.6130e-02,\n",
       "                       -1.6326e-02, -9.3399e-02,  1.3939e-02, -2.8116e-02, -1.1573e-01,\n",
       "                        9.0672e-03,  6.6254e-02, -4.4050e-02,  7.0229e-02, -4.4339e-02,\n",
       "                       -1.1449e-01, -1.3835e-01,  4.8635e-02, -9.7143e-02, -1.1634e-01,\n",
       "                       -4.9575e-03,  1.1319e-03,  1.3320e-02,  1.0254e-01,  3.7221e-03,\n",
       "                       -4.4214e-02, -8.6572e-02,  8.0780e-02, -6.7103e-02, -9.1340e-02,\n",
       "                        1.0789e-01,  1.7689e-02, -5.2360e-02,  5.8920e-03,  8.4343e-02,\n",
       "                       -9.8393e-02,  9.1523e-02,  5.0927e-02, -9.2766e-02,  3.7558e-02,\n",
       "                        2.4212e-02, -7.5794e-02, -5.6300e-02, -1.3136e-01, -1.1751e-01,\n",
       "                       -2.1679e-02, -3.5190e-03, -4.2948e-02,  3.8875e-02,  4.3832e-02,\n",
       "                        1.4075e-02,  4.5327e-02,  1.0959e-01,  6.3354e-02, -1.3196e-01],\n",
       "                      [-7.2861e-02, -4.3499e-02, -7.9535e-02, -2.0590e-02,  4.0295e-02,\n",
       "                        8.6614e-02,  3.3214e-02, -7.6406e-02,  1.8294e-02, -1.4236e-01,\n",
       "                        8.6758e-02, -1.3586e-01, -4.3289e-02, -1.1338e-01, -1.4908e-01,\n",
       "                       -5.8430e-02,  3.7743e-02,  6.6474e-02, -1.6071e-01, -6.5442e-02,\n",
       "                       -9.0469e-02,  7.5546e-02, -8.7734e-02, -2.4916e-02, -6.0102e-02,\n",
       "                       -1.5291e-01, -6.4047e-02, -7.8400e-03, -5.6800e-02,  1.0140e-02,\n",
       "                        7.7112e-02, -1.1326e-01,  2.5516e-03,  8.1821e-02,  7.1829e-02,\n",
       "                       -6.3364e-02,  2.1533e-02,  6.4882e-02,  1.7553e-02,  1.0030e-02,\n",
       "                       -4.5291e-02, -7.7193e-02,  9.7117e-03,  5.7783e-03, -1.5310e-01,\n",
       "                       -2.1337e-03,  4.3211e-02, -1.2148e-01,  1.0396e-02,  3.0958e-03,\n",
       "                        1.1266e-02,  5.9609e-02,  7.5139e-02, -7.7047e-02, -2.5317e-02,\n",
       "                        6.2294e-02, -4.9516e-02, -1.6889e-01, -1.3113e-01, -6.2186e-02],\n",
       "                      [-1.4847e-01, -2.6456e-02,  2.0024e-02,  9.0909e-02,  9.0948e-02,\n",
       "                        6.1125e-02,  4.1422e-02,  5.5889e-02, -5.7107e-03, -1.0557e-01,\n",
       "                       -4.9085e-02,  6.4660e-02,  8.9131e-02,  2.9172e-02,  7.6949e-02,\n",
       "                        6.5358e-02,  9.4248e-02,  1.4650e-02,  5.4662e-02,  9.4836e-02,\n",
       "                       -7.1306e-02, -1.3754e-01, -1.2518e-02, -9.1217e-02, -6.0145e-04,\n",
       "                       -9.5739e-02, -8.3600e-02, -1.5496e-01,  3.7475e-02, -8.6315e-03,\n",
       "                        7.6740e-02, -1.5411e-01, -3.0751e-02,  6.9316e-03, -1.2826e-01,\n",
       "                        2.0325e-02, -1.5764e-01,  5.7475e-03, -9.0799e-02, -1.4114e-01,\n",
       "                        8.2274e-02,  3.1222e-02,  6.9092e-02, -1.2871e-01, -6.9550e-02,\n",
       "                       -1.4954e-01, -8.3086e-02, -1.1442e-01, -1.2095e-01,  5.6271e-02,\n",
       "                        6.3643e-02,  5.4181e-02, -7.5784e-02, -8.9377e-02,  9.2715e-02,\n",
       "                        1.2102e-02,  2.0490e-03, -1.1435e-01, -8.1576e-02, -1.0072e-03]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 1.1409,  0.6862,  0.0896,  0.5709, -0.0761,  0.0448,  0.0789,  0.1057,\n",
       "                      -0.0533,  0.5998, -0.1116,  0.0645,  0.0509, -0.0248,  0.0118, -0.1331])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.1269,  0.2952, -0.2417, -0.1128, -0.0278, -0.1295,  0.1388, -0.1950,\n",
       "                        0.0296, -0.2562, -0.0006, -0.1130, -0.0919, -0.2358, -0.0963, -0.0318],\n",
       "                      [-0.2487,  0.1882, -0.2072,  0.1717,  0.1789,  0.1928,  0.1736,  0.1753,\n",
       "                       -0.2231,  0.1471, -0.0314,  0.0657, -0.1477,  0.1522,  0.1333,  0.1941],\n",
       "                      [-0.0056, -0.1737, -0.1346, -0.2714, -0.0886,  0.1231,  0.0411,  0.0568,\n",
       "                        0.2158, -0.0024,  0.0927, -0.0933,  0.2207,  0.1663, -0.0235,  0.2049],\n",
       "                      [-0.0159, -0.0083, -0.0026, -0.1342,  0.1043, -0.1885, -0.0727, -0.2335,\n",
       "                       -0.1810, -0.0588, -0.1103,  0.1892, -0.1737,  0.1768,  0.0541,  0.2087],\n",
       "                      [-0.5365,  0.0185, -0.2068,  0.2706,  0.1237, -0.2443, -0.0224, -0.0853,\n",
       "                       -0.0295,  0.4977, -0.0818,  0.1699, -0.1310, -0.0397,  0.2174,  0.0493],\n",
       "                      [-0.1083,  0.2258,  0.0429,  0.2657,  0.1697, -0.1276, -0.1184, -0.1668,\n",
       "                        0.1824,  0.0127, -0.1578,  0.0401, -0.0628,  0.2302, -0.1537, -0.1225],\n",
       "                      [ 0.0145, -0.0835, -0.1981,  0.1086, -0.2166, -0.0841,  0.0345,  0.2341,\n",
       "                        0.2245, -0.0274,  0.0410,  0.0987, -0.1821, -0.0043, -0.0036, -0.2304],\n",
       "                      [ 0.3614,  0.0076,  0.2271, -0.0271, -0.0553,  0.0462, -0.2232,  0.1540,\n",
       "                       -0.2473, -0.2624, -0.0154,  0.1155,  0.2772,  0.1662, -0.1366,  0.0092]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0458, -0.1930, -0.1967, -0.1112,  0.0665,  0.3924, -0.3321,  0.8172])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 4.0776e-04, -1.1168e-01, -2.4602e-02, -2.3245e-01,  6.7537e-02,\n",
       "                        2.5009e-01, -1.3685e-03,  4.0874e-02],\n",
       "                      [ 3.5469e-01, -2.6759e-01, -1.2478e-02, -1.8003e-01,  4.4412e-01,\n",
       "                        1.2131e-01,  6.7747e-02, -4.6076e-02],\n",
       "                      [-3.8567e-01, -4.8115e-02, -4.9592e-02,  1.4496e-01,  3.7466e-01,\n",
       "                        1.7306e-01,  1.7599e-02,  4.7791e-01]])),\n",
       "             ('fc3.bias', tensor([0.7886, 0.1372, 0.3698])),\n",
       "             ('fc4.weight',\n",
       "              tensor([[ 0.5476,  0.2069,  0.4926],\n",
       "                      [-0.1332,  0.4819,  0.5933],\n",
       "                      [ 0.0859, -0.2419,  0.4304]])),\n",
       "             ('fc4.bias', tensor([0.0827, 0.6051, 0.8802]))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fc3915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745bdcd",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d475a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.cnn_model(self)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "017df39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 model.load_state_dict(checkpoint[<span style=\"color: #808000; text-decoration-color: #808000\">'model_state_dict'</span>])                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'model_state_dict'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 model.load_state_dict(checkpoint[\u001b[33m'\u001b[0m\u001b[33mmodel_state_dict\u001b[0m\u001b[33m'\u001b[0m])                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'model_state_dict'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4997dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ =  YourModel(10,6,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faf0a404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 model_.load_state_dict(checkpoint)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda3/envs/deepq/lib/python3.8/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2041</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_state_dict</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2038 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">', '</span>.join(<span style=\"color: #808000; text-decoration-color: #808000\">'\"{}\"'</span>.format(k) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> missing_keys)))               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2039 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2040 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(error_msgs) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2041 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'Error(s) in loading state_dict for {}:\\n\\t{}'</span>.format(     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2042 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │      </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\\t\"</span>.join(error_msgs)))         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2043 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _IncompatibleKeys(missing_keys, unexpected_keys)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2044 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Error</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span> in loading state_dict for YourModel:\n",
       "        size mismatch for fc4.weight: copying a param with shape <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span> from checkpoint, the shape in \n",
       "current model is <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span>.\n",
       "        size mismatch for fc4.bias: copying a param with shape <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span> from checkpoint, the shape in \n",
       "current model is <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">])</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 model_.load_state_dict(checkpoint)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda3/envs/deepq/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m2041\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mload_state_dict\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2038 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m.join(\u001b[33m'\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m'\u001b[0m.format(k) \u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m missing_keys)))               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2039 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2040 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(error_msgs) > \u001b[94m0\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2041 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33m'\u001b[0m\u001b[33mError(s) in loading state_dict for \u001b[0m\u001b[33m{}\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\t\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2042 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\t\u001b[0m\u001b[33m\"\u001b[0m.join(error_msgs)))         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2043 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _IncompatibleKeys(missing_keys, unexpected_keys)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2044 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0m\u001b[1;35mError\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m in loading state_dict for YourModel:\n",
       "        size mismatch for fc4.weight: copying a param with shape \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m from checkpoint, the shape in \n",
       "current model is \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m.\n",
       "        size mismatch for fc4.bias: copying a param with shape \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m from checkpoint, the shape in \n",
       "current model is \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_.load_state_dict(checkpoint) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75c02a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 model_.load_state_dict(torch.load(<span style=\"color: #808000; text-decoration-color: #808000\">'model1.pth'</span>))                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda3/envs/deepq/lib/python3.8/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2041</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_state_dict</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2038 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">', '</span>.join(<span style=\"color: #808000; text-decoration-color: #808000\">'\"{}\"'</span>.format(k) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> missing_keys)))               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2039 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2040 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(error_msgs) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2041 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'Error(s) in loading state_dict for {}:\\n\\t{}'</span>.format(     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2042 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │      </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\\t\"</span>.join(error_msgs)))         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2043 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _IncompatibleKeys(missing_keys, unexpected_keys)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2044 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Error</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span> in loading state_dict for YourModel:\n",
       "        size mismatch for fc4.weight: copying a param with shape <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span> from checkpoint, the shape in \n",
       "current model is <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span>.\n",
       "        size mismatch for fc4.bias: copying a param with shape <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">])</span> from checkpoint, the shape in \n",
       "current model is <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">])</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 model_.load_state_dict(torch.load(\u001b[33m'\u001b[0m\u001b[33mmodel1.pth\u001b[0m\u001b[33m'\u001b[0m))                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda3/envs/deepq/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m2041\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mload_state_dict\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2038 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m.join(\u001b[33m'\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m'\u001b[0m.format(k) \u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m missing_keys)))               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2039 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2040 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(error_msgs) > \u001b[94m0\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2041 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33m'\u001b[0m\u001b[33mError(s) in loading state_dict for \u001b[0m\u001b[33m{}\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\t\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2042 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\t\u001b[0m\u001b[33m\"\u001b[0m.join(error_msgs)))         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2043 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _IncompatibleKeys(missing_keys, unexpected_keys)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2044 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0m\u001b[1;35mError\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m in loading state_dict for YourModel:\n",
       "        size mismatch for fc4.weight: copying a param with shape \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m from checkpoint, the shape in \n",
       "current model is \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m.\n",
       "        size mismatch for fc4.bias: copying a param with shape \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m from checkpoint, the shape in \n",
       "current model is \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_.load_state_dict(torch.load('model1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da0085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (rl_trading)",
   "language": "python",
   "name": "kedro_rl_trading"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
