# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html

RAW_ICHI:
  type: pandas.CSVDataSet
  filepath: data/01_raw/SET_DLY_ICHI_MA9,D.csv
  load_args:
    sep: ','
  save_args:
    date_format: '%Y-%m-%d'
  layer: raw

# temporary data
# when the pipeline is completed, all the data stored in the MemoryDataset objects within that pipeline will be cleared or released.
ichi:
  type: MemoryDataSet 
  layer: intermediate
train_df:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/train_df.pq
  layer: primary
test_df:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/test_df.pq
  layer: primary
train_info:
  type: MemoryDataSet 
  layer: model_input
test_info:
  type: MemoryDataSet 
  layer: model_input

# show correlation
raw_correlation_matrix:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/raw_data_correlation.png
  layer: feature

train_data_correlation_matrix:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/train_data_correlation.png
  layer: model_input

result_data:
  type: json.JSONDataSet
  filepath: data/08_reporting/output_data.json
  versioned: true
  layer: model_output

result_plot:
  type: plotly.JSONDataSet
  filepath: data/08_reporting/output_data_plot.json
  versioned: true
  layer: model_output
